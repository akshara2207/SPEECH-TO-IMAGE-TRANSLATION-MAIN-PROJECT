**INTRODUCTION** 
 
The project area for speech-to-image translation, focusing on speech-to-text conversion via speech
recognition and text-to-image generation using sentence-transformer models trained on the Oxford
102 Flower dataset and CUB-200-2011 Bird Dataset, encompasses the intersection of natural language processing, computer vision, and deep learning. This multidisciplinary field aims to develop
robust systems that can accurately translate spoken language into visual images based on textual descriptions. By leveraging state-of-the-art speech recognition algorithms, the project ensures precise
conversion of spoken words into written text, laying the foundation for semantic understanding.

**SYSTEM ARCHITECTURE** 

![image](https://github.com/akshara2207/SPEECH-TO-IMAGE-TRANSLATION-MAIN-PROJECT/assets/117832952/add27cf4-58ab-4e78-b8b6-a0233d63a75d)


**LANGUAGE** :
Python 

**FRAMEWORK USED**:
Flask


**TECHOLOGIES USED** :

• Speech Recognition

• Sentence-Transformer 

**APPLICATIONS** :

• Assistive Technology for Visually Impaired

• Educational Tools

• Creative Projects and Design Work
